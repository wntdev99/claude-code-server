# Checkpoint System (ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ)

ì´ ë¬¸ì„œëŠ” Claude Code Serverì˜ Checkpoint ì‹œìŠ¤í…œì„ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## ê°œìš”

CheckpointëŠ” **Agentì˜ í˜„ì¬ ìƒíƒœë¥¼ ìŠ¤ëƒ…ìƒ·ìœ¼ë¡œ ì €ì¥**í•˜ì—¬ ë‚˜ì¤‘ì— ë³µêµ¬í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### ëª©ì 

1. **ì¥ì•  ë³µêµ¬**: ì‹œìŠ¤í…œ crash ì‹œ ì‘ì—… ì†ì‹¤ ë°©ì§€
2. **Rate Limit ëŒ€ì‘**: API ì œí•œ ì‹œ ì¼ì‹œì¤‘ì§€ í›„ ìë™ ì¬ê°œ
3. **ì‚¬ìš©ì ì œì–´**: ìˆ˜ë™ ì¼ì‹œì¤‘ì§€ ë° ì¬ê°œ
4. **ì—ëŸ¬ ë³µêµ¬**: ì—ëŸ¬ ë°œìƒ ì‹œ ì´ì „ ìƒíƒœë¡œ ë¡¤ë°±

### í•µì‹¬ ì›ì¹™

```
"ì‘ì—… ë””ë ‰í† ë¦¬(Workspace)ê°€ Single Source of Truth"

ëª¨ë“  ìƒíƒœëŠ” íŒŒì¼ ì‹œìŠ¤í…œì— ì €ì¥ë˜ë©°,
ì‹œìŠ¤í…œì´ ì¬ì‹œì‘ë˜ì–´ë„ Workspaceì—ì„œ ë³µêµ¬ ê°€ëŠ¥
```

---

## Checkpoint ìƒì„± ì‹œì 

### ìë™ ìƒì„±

#### 1. ì£¼ê¸°ì  ìë™ ì €ì¥ (10ë¶„ë§ˆë‹¤)
```
Agent ì‹¤í–‰ ì¤‘
   â†“
10ë¶„ ê²½ê³¼
   â†“
Checkpoint ìë™ ìƒì„±
   â†“
ê³„ì† ì‹¤í–‰
```

**ì„¤ì •**:
```typescript
const AUTO_CHECKPOINT_INTERVAL = 10 * 60 * 1000; // 10ë¶„ (ë°€ë¦¬ì´ˆ)

setInterval(() => {
  if (agent.status === 'running') {
    createCheckpoint(agent.taskId);
  }
}, AUTO_CHECKPOINT_INTERVAL);
```

#### 2. Rate Limit ê°ì§€ ì‹œ
```
Agent ì‹¤í–‰ ì¤‘
   â†“
[ERROR] type: recoverable, message: Rate limit exceeded
   â†“
Checkpoint ìƒì„±
   â†“
Agent ì¼ì‹œì¤‘ì§€ (SIGTSTP)
   â†“
Rate Limit reset ëŒ€ê¸°
   â†“
Agent ìë™ ì¬ê°œ (SIGCONT)
```

#### 3. ì—ëŸ¬ ë°œìƒ ì‹œ
```
Agent ì‹¤í–‰ ì¤‘
   â†“
[ERROR] (any type)
   â†“
Checkpoint ìƒì„± (í˜„ì¬ ìƒíƒœ ë³´ì¡´)
   â†“
ì—ëŸ¬ íƒ€ì…ì— ë”°ë¼ ì²˜ë¦¬:
  - recoverable: ì¬ì‹œë„
  - fatal: Task ì‹¤íŒ¨
```

#### 4. Phase ì™„ë£Œ ì‹œ
```
Phase N ì™„ë£Œ
   â†“
=== PHASE N COMPLETE ===
   â†“
Checkpoint ìƒì„±
   â†“
Agent ì¼ì‹œì¤‘ì§€
   â†“
ê²€ì¦ â†’ ë¦¬ë·°
   â†“
ìŠ¹ì¸ ì‹œ Phase N+1 ì‹œì‘
```

### ìˆ˜ë™ ìƒì„±

#### ì‚¬ìš©ìê°€ "ì¼ì‹œì¤‘ì§€" í´ë¦­
```
ì›¹ UIì—ì„œ "Pause" ë²„íŠ¼ í´ë¦­
   â†“
Checkpoint ìƒì„±
   â†“
Agent ì¼ì‹œì¤‘ì§€ (SIGTSTP)
```

---

## Checkpoint êµ¬ì¡°

### íŒŒì¼ ìœ„ì¹˜

```
/projects/{task-id}/.checkpoints/
â”œâ”€â”€ checkpoint_2024-02-15T10-30-00.json   # ìë™ (10ë¶„ë§ˆë‹¤)
â”œâ”€â”€ checkpoint_2024-02-15T10-40-00.json   # ìë™ (10ë¶„ë§ˆë‹¤)
â”œâ”€â”€ checkpoint_phase_complete_1708000800000.json  # Phase ì™„ë£Œ
â”œâ”€â”€ checkpoint_rate_limit_1708000200000.json      # Rate Limit
â”œâ”€â”€ checkpoint_manual_1708000500000.json          # ì‚¬ìš©ì ì¼ì‹œì¤‘ì§€ (manual)
â””â”€â”€ (ìµœì‹  10ê°œ íŒŒì¼ë§Œ ë³´ì¡´, ì´ì „ íŒŒì¼ì€ ìë™ ì‚­ì œ)
```

### Checkpoint ë°ì´í„° êµ¬ì¡°

```typescript
interface Checkpoint {
  // ë©”íƒ€ë°ì´í„°
  id: string;                           // checkpoint_abc123
  taskId: string;                       // task_xyz789
  createdAt: string;                    // ISO 8601 timestamp
  createdBy: 'auto' | 'user' | 'system';
  reason: string;                       // 'interval' | 'rate_limit' | 'error' | 'phase_complete' | 'manual'

  // Task ìƒíƒœ
  task: {
    status: TaskStatus;                 // 'in_progress', 'review', etc.
    type: TaskType;                     // 'create_app', etc.
    currentPhase: number | null;        // 1, 2, 3, 4
    progress: number;                   // 0-100
  };

  // Agent ìƒíƒœ
  agent: {
    status: AgentStatus;                // 'running', 'paused', etc.
    pid: number;                        // Process ID
    currentPhase: number | null;
    currentStep: string | null;         // '03_users'
    tokensUsed: number;
    blockedBy: string | null;
  };

  // ëŒ€í™” íˆìŠ¤í† ë¦¬
  conversationHistory: {
    messages: ConversationMessage[];    // ëª¨ë“  ëŒ€í™” ë‚´ì—­
    lastMessageIndex: number;           // ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì¸ë±ìŠ¤
  };

  // í™˜ê²½ ë³€ìˆ˜
  environment: {
    variables: Record<string, string>;  // ì•”í˜¸í™”ëœ í™˜ê²½ ë³€ìˆ˜
    dependencies: Dependency[];         // ì œê³µëœ ì˜ì¡´ì„± ëª©ë¡
  };

  // ì‘ì—… ë””ë ‰í† ë¦¬ ìƒíƒœ
  workspace: {
    path: string;                       // /projects/task_xyz789/
    deliverables: string[];             // ìƒì„±ëœ íŒŒì¼ ëª©ë¡
    lastModified: string;               // ë§ˆì§€ë§‰ ìˆ˜ì • ì‹œê°„
  };

  // í”„ë¡œí† ì½œ ìƒíƒœ
  protocols: {
    pendingDependencies: DependencyRequest[];
    pendingQuestions: UserQuestion[];
    completedPhases: number[];
  };
}

interface ConversationMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
  timestamp: string;
  metadata?: {
    phase?: number;
    step?: string;
    type?: 'protocol' | 'log' | 'error';
  };
}
```

### ì˜ˆì‹œ Checkpoint JSON

```json
{
  "id": "checkpoint_abc123",
  "taskId": "task_xyz789",
  "createdAt": "2024-02-15T10:30:00Z",
  "createdBy": "auto",
  "reason": "interval",

  "task": {
    "status": "in_progress",
    "type": "create_app",
    "currentPhase": 1,
    "progress": 35
  },

  "agent": {
    "status": "running",
    "pid": 12345,
    "currentPhase": 1,
    "currentStep": "03_users",
    "tokensUsed": 12500,
    "blockedBy": null
  },

  "conversationHistory": {
    "messages": [
      {
        "role": "system",
        "content": "You are a sub-agent executing Phase 1 (Planning)...",
        "timestamp": "2024-02-15T10:00:00Z"
      },
      {
        "role": "assistant",
        "content": "I'll start by reading guide/planning/01_idea.md...",
        "timestamp": "2024-02-15T10:01:00Z"
      }
    ],
    "lastMessageIndex": 25
  },

  "environment": {
    "variables": {
      "OPENAI_API_KEY": "encrypted:abc123..."
    },
    "dependencies": [
      {
        "type": "api_key",
        "name": "OPENAI_API_KEY",
        "providedAt": "2024-02-15T10:05:00Z"
      }
    ]
  },

  "workspace": {
    "path": "/projects/task_xyz789/",
    "deliverables": [
      "docs/planning/01_idea.md",
      "docs/planning/02_market.md",
      "docs/planning/03_users.md"
    ],
    "lastModified": "2024-02-15T10:29:50Z"
  },

  "protocols": {
    "pendingDependencies": [],
    "pendingQuestions": [],
    "completedPhases": []
  }
}
```

---

## Checkpoint ìƒì„± í”„ë¡œì„¸ìŠ¤

### 1. ìƒíƒœ ìˆ˜ì§‘

```typescript
async function createCheckpoint(taskId: string, reason: string): Promise<Checkpoint> {
  // 1. Task ìƒíƒœ ì¡°íšŒ
  const task = await db.task.findUnique({ where: { id: taskId } });

  // 2. Agent ìƒíƒœ ì¡°íšŒ
  const agent = await getAgentStatus(taskId);

  // 3. ëŒ€í™” íˆìŠ¤í† ë¦¬ ìˆ˜ì§‘
  const conversationHistory = await getConversationHistory(taskId);

  // 4. í™˜ê²½ ë³€ìˆ˜ ìˆ˜ì§‘
  const environment = await getEnvironmentVariables(taskId);

  // 5. Workspace ìŠ¤ìº”
  const workspace = await scanWorkspace(taskId);

  // 6. í”„ë¡œí† ì½œ ìƒíƒœ ìˆ˜ì§‘
  const protocols = await getProtocolState(taskId);

  // 7. Checkpoint ê°ì²´ ìƒì„±
  const checkpoint: Checkpoint = {
    id: generateCheckpointId(),
    taskId,
    createdAt: new Date().toISOString(),
    createdBy: reason === 'manual' ? 'user' : 'system',
    reason,
    task: extractTaskState(task),
    agent: extractAgentState(agent),
    conversationHistory,
    environment,
    workspace,
    protocols,
  };

  return checkpoint;
}
```

### 2. íŒŒì¼ ì €ì¥

```typescript
async function saveCheckpoint(checkpoint: Checkpoint): Promise<void> {
  const checkpointDir = `/projects/${checkpoint.taskId}/.checkpoints/`;
  const filename = `checkpoint_${checkpoint.createdAt.replace(/[:.]/g, '-')}.json`;
  const filepath = path.join(checkpointDir, filename);

  // 1. ë””ë ‰í† ë¦¬ í™•ì¸
  await fs.mkdir(checkpointDir, { recursive: true });

  // 2. JSON íŒŒì¼ ì €ì¥
  await fs.writeFile(filepath, JSON.stringify(checkpoint, null, 2));

  // 3. latest.json ì‹¬ë³¼ë¦­ ë§í¬ ì—…ë°ì´íŠ¸
  const latestPath = path.join(checkpointDir, 'latest.json');
  await fs.unlink(latestPath).catch(() => {}); // ê¸°ì¡´ ë§í¬ ì‚­ì œ (ì—ëŸ¬ ë¬´ì‹œ)
  await fs.symlink(filename, latestPath);

  // 4. DBì— Checkpoint ë ˆì½”ë“œ ìƒì„±
  await db.checkpoint.create({
    data: {
      id: checkpoint.id,
      taskId: checkpoint.taskId,
      filepath,
      createdAt: checkpoint.createdAt,
      reason: checkpoint.reason,
    },
  });

  console.log(`âœ… Checkpoint saved: ${filepath}`);
}
```

### 3. ì •ë¦¬ (Cleanup)

ì˜¤ë˜ëœ Checkpoint ìë™ ì‚­ì œ:

```typescript
async function cleanupOldCheckpoints(taskId: string): Promise<void> {
  const checkpointDir = `/projects/${taskId}/.checkpoints/`;
  const files = await fs.readdir(checkpointDir);

  // 1. ìƒì„± ì‹œê°„ ê¸°ì¤€ ì •ë ¬
  const checkpoints = files
    .filter(f => f.startsWith('checkpoint_') && f.endsWith('.json'))
    .map(f => ({
      filename: f,
      createdAt: extractTimestamp(f),
    }))
    .sort((a, b) => b.createdAt.getTime() - a.createdAt.getTime());

  // 2. ìµœì‹  10ê°œë§Œ ìœ ì§€
  const MAX_CHECKPOINTS = 10;
  const toDelete = checkpoints.slice(MAX_CHECKPOINTS);

  // 3. ì‚­ì œ
  for (const checkpoint of toDelete) {
    await fs.unlink(path.join(checkpointDir, checkpoint.filename));
    console.log(`ğŸ—‘ï¸  Old checkpoint deleted: ${checkpoint.filename}`);
  }
}
```

---

## File Size Limits (íŒŒì¼ í¬ê¸° ì œí•œ)

### ë¬¸ì œ ìƒí™©

Agentê°€ ê³¼ë„í•˜ê²Œ í° íŒŒì¼ì„ ìƒì„±í•˜ì—¬ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ë¥¼ ê³ ê°ˆì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

**ë¬¸ì œê°€ ìˆëŠ” ì‹œë‚˜ë¦¬ì˜¤**:
- 100MB+ í¬ê¸°ì˜ ë‹¨ì¼ ì†ŒìŠ¤ ì½”ë“œ íŒŒì¼
- ê±°ëŒ€í•œ ë¡œê·¸ íŒŒì¼ (ìˆ˜ GB)
- ê³¼ë„í•˜ê²Œ í° Checkpoint íŒŒì¼
- ì „ì²´ Workspaceê°€ ìˆ˜ GB ì´ˆê³¼

**ë¬¸ì œì **:
- ë©”ëª¨ë¦¬ ë¶€ì¡± (OOM) ì—ëŸ¬
- ë””ìŠ¤í¬ ê³µê°„ ê³ ê°ˆ
- ëŠë¦° íŒŒì¼ I/O
- Checkpoint ë³µêµ¬ ì‹¤íŒ¨
- ë°±ì—… ì‹œìŠ¤í…œ ê³¼ë¶€í•˜

### í•´ê²° ë°©ì•ˆ

íŒŒì¼ íƒ€ì…ë³„ í¬ê¸° ì œí•œì„ ì„¤ì •í•˜ê³  ê°•ì œ:

#### 1. íŒŒì¼ í¬ê¸° ì œí•œ ì •ì˜

```typescript
// packages/shared/src/config/fileSizeLimits.ts

/**
 * íŒŒì¼ íƒ€ì…ë³„ í¬ê¸° ì œí•œ (ë°”ì´íŠ¸ ë‹¨ìœ„)
 */
export const FILE_SIZE_LIMITS = {
  // ì†ŒìŠ¤ ì½”ë“œ íŒŒì¼
  sourceCode: {
    maxSize: 10 * 1024 * 1024,        // 10 MB
    extensions: ['.js', '.ts', '.jsx', '.tsx', '.py', '.java', '.go', '.rs', '.c', '.cpp'],
  },

  // ë¬¸ì„œ íŒŒì¼
  documentation: {
    maxSize: 5 * 1024 * 1024,         // 5 MB
    extensions: ['.md', '.txt', '.rst', '.adoc'],
  },

  // ì„¤ì • íŒŒì¼
  configuration: {
    maxSize: 1 * 1024 * 1024,         // 1 MB
    extensions: ['.json', '.yaml', '.yml', '.toml', '.ini', '.env'],
  },

  // Checkpoint íŒŒì¼
  checkpoint: {
    maxSize: 50 * 1024 * 1024,        // 50 MB
    extensions: ['.checkpoint', '.json'],
  },

  // ë¡œê·¸ íŒŒì¼
  logs: {
    maxSize: 100 * 1024 * 1024,       // 100 MB
    extensions: ['.log'],
  },

  // ì´ë¯¸ì§€ íŒŒì¼
  images: {
    maxSize: 10 * 1024 * 1024,        // 10 MB
    extensions: ['.png', '.jpg', '.jpeg', '.gif', '.svg', '.webp'],
  },

  // ê¸°íƒ€ íŒŒì¼ (ê¸°ë³¸ê°’)
  default: {
    maxSize: 20 * 1024 * 1024,        // 20 MB
    extensions: [],
  },
};

/**
 * Workspace ì „ì²´ í¬ê¸° ì œí•œ
 */
export const WORKSPACE_LIMITS = {
  maxTotalSize: 500 * 1024 * 1024,    // 500 MB
  maxFileCount: 10000,                 // ìµœëŒ€ 10,000ê°œ íŒŒì¼
};

/**
 * íŒŒì¼ í™•ì¥ìë¡œ ì¹´í…Œê³ ë¦¬ ê²°ì •
 */
export function getFileSizeLimit(filename: string): number {
  const ext = path.extname(filename).toLowerCase();

  for (const [category, config] of Object.entries(FILE_SIZE_LIMITS)) {
    if (category === 'default') continue;

    if (config.extensions.includes(ext)) {
      return config.maxSize;
    }
  }

  return FILE_SIZE_LIMITS.default.maxSize;
}
```

#### 2. íŒŒì¼ í¬ê¸° ëª¨ë‹ˆí„°ë§ ë° ê²€ì¦

```typescript
// packages/shared/src/utils/fileSizeValidator.ts

import fs from 'fs/promises';
import path from 'path';
import { getFileSizeLimit, WORKSPACE_LIMITS } from '../config/fileSizeLimits';

/**
 * íŒŒì¼ í¬ê¸° ê²€ì¦ê¸°
 */
export class FileSizeValidator {
  /**
   * íŒŒì¼ í¬ê¸° ê²€ì¦ (ìƒì„± ì „)
   */
  static validateFileSize(
    filename: string,
    contentSize: number
  ): ValidationResult {
    const maxSize = getFileSizeLimit(filename);

    if (contentSize > maxSize) {
      return {
        valid: false,
        error: `File size exceeds limit: ${this.formatBytes(contentSize)} > ${this.formatBytes(maxSize)}`,
        maxSize,
        actualSize: contentSize,
      };
    }

    return {
      valid: true,
      maxSize,
      actualSize: contentSize,
    };
  }

  /**
   * ê¸°ì¡´ íŒŒì¼ í¬ê¸° í™•ì¸
   */
  static async checkExistingFile(filePath: string): Promise<FileSizeInfo> {
    try {
      const stats = await fs.stat(filePath);
      const filename = path.basename(filePath);
      const maxSize = getFileSizeLimit(filename);

      return {
        path: filePath,
        size: stats.size,
        maxSize,
        exceedsLimit: stats.size > maxSize,
        percentUsed: (stats.size / maxSize) * 100,
      };
    } catch (error) {
      throw new Error(`Failed to check file size: ${error.message}`);
    }
  }

  /**
   * Workspace ì „ì²´ í¬ê¸° í™•ì¸
   */
  static async checkWorkspaceSize(workspacePath: string): Promise<WorkspaceSizeInfo> {
    let totalSize = 0;
    let fileCount = 0;
    const oversizedFiles: string[] = [];

    // ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“  íŒŒì¼ ìŠ¤ìº”
    async function scanDirectory(dirPath: string): Promise<void> {
      const entries = await fs.readdir(dirPath, { withFileTypes: true });

      for (const entry of entries) {
        const fullPath = path.join(dirPath, entry.name);

        if (entry.isDirectory()) {
          // íŠ¹ì • ë””ë ‰í† ë¦¬ ì œì™¸ (node_modules, .git ë“±)
          if (!entry.name.startsWith('.') && entry.name !== 'node_modules') {
            await scanDirectory(fullPath);
          }
        } else if (entry.isFile()) {
          const stats = await fs.stat(fullPath);
          totalSize += stats.size;
          fileCount++;

          // íŒŒì¼ í¬ê¸° ì œí•œ ì²´í¬
          const maxSize = getFileSizeLimit(entry.name);
          if (stats.size > maxSize) {
            oversizedFiles.push(fullPath);
          }
        }
      }
    }

    await scanDirectory(workspacePath);

    return {
      totalSize,
      fileCount,
      maxTotalSize: WORKSPACE_LIMITS.maxTotalSize,
      maxFileCount: WORKSPACE_LIMITS.maxFileCount,
      exceedsSizeLimit: totalSize > WORKSPACE_LIMITS.maxTotalSize,
      exceedsFileCountLimit: fileCount > WORKSPACE_LIMITS.maxFileCount,
      percentUsed: (totalSize / WORKSPACE_LIMITS.maxTotalSize) * 100,
      oversizedFiles,
    };
  }

  /**
   * ë°”ì´íŠ¸ë¥¼ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
   */
  static formatBytes(bytes: number): string {
    if (bytes === 0) return '0 Bytes';

    const k = 1024;
    const sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB'];
    const i = Math.floor(Math.log(bytes) / Math.log(k));

    return `${(bytes / Math.pow(k, i)).toFixed(2)} ${sizes[i]}`;
  }
}

interface ValidationResult {
  valid: boolean;
  error?: string;
  maxSize: number;
  actualSize: number;
}

interface FileSizeInfo {
  path: string;
  size: number;
  maxSize: number;
  exceedsLimit: boolean;
  percentUsed: number;
}

interface WorkspaceSizeInfo {
  totalSize: number;
  fileCount: number;
  maxTotalSize: number;
  maxFileCount: number;
  exceedsSizeLimit: boolean;
  exceedsFileCountLimit: boolean;
  percentUsed: number;
  oversizedFiles: string[];
}
```

#### 3. Streaming Write for Large Files

```typescript
// packages/shared/src/utils/streamingFileWriter.ts

import { createWriteStream, WriteStream } from 'fs';
import { pipeline } from 'stream/promises';
import { Readable } from 'stream';

/**
 * ìŠ¤íŠ¸ë¦¬ë° íŒŒì¼ ì“°ê¸° (ëŒ€ìš©ëŸ‰ íŒŒì¼ìš©)
 */
export class StreamingFileWriter {
  private stream: WriteStream;
  private bytesWritten: number = 0;
  private readonly maxSize: number;

  constructor(filePath: string, maxSize: number) {
    this.stream = createWriteStream(filePath);
    this.maxSize = maxSize;
  }

  /**
   * ì²­í¬ ë‹¨ìœ„ë¡œ ì“°ê¸°
   */
  async writeChunk(chunk: string | Buffer): Promise<void> {
    const chunkSize = Buffer.byteLength(chunk);

    // í¬ê¸° ì œí•œ í™•ì¸
    if (this.bytesWritten + chunkSize > this.maxSize) {
      throw new FileSizeExceededError(
        `File size would exceed limit: ${this.bytesWritten + chunkSize} > ${this.maxSize}`
      );
    }

    return new Promise((resolve, reject) => {
      const canContinue = this.stream.write(chunk);

      this.bytesWritten += chunkSize;

      if (canContinue) {
        resolve();
      } else {
        this.stream.once('drain', resolve);
        this.stream.once('error', reject);
      }
    });
  }

  /**
   * ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
   */
  async close(): Promise<void> {
    return new Promise((resolve, reject) => {
      this.stream.end(() => resolve());
      this.stream.once('error', reject);
    });
  }

  /**
   * í˜„ì¬ê¹Œì§€ ì“°ì¸ ë°”ì´íŠ¸ ìˆ˜
   */
  getBytesWritten(): number {
    return this.bytesWritten;
  }
}

class FileSizeExceededError extends Error {
  constructor(message: string) {
    super(message);
    this.name = 'FileSizeExceededError';
  }
}

/**
 * ëŒ€ìš©ëŸ‰ ì½˜í…ì¸ ë¥¼ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì“°ê¸°
 */
export async function writeStreamingSafe(
  filePath: string,
  contentStream: Readable,
  maxSize: number
): Promise<void> {
  const writer = new StreamingFileWriter(filePath, maxSize);

  try {
    for await (const chunk of contentStream) {
      await writer.writeChunk(chunk);
    }

    await writer.close();

    console.log(`âœ… File written via streaming: ${filePath} (${writer.getBytesWritten()} bytes)`);
  } catch (error) {
    // ì—ëŸ¬ ë°œìƒ ì‹œ ë¶€ë¶„ì ìœ¼ë¡œ ì“°ì¸ íŒŒì¼ ì‚­ì œ
    await fs.unlink(filePath).catch(() => {});

    throw error;
  }
}
```

#### 4. Size Limit Enforcement (Agent Manager)

```typescript
// packages/agent-manager/src/deliverables/SizeEnforcer.ts

import { FileSizeValidator } from '@shared/utils/fileSizeValidator';

/**
 * ì‚°ì¶œë¬¼ í¬ê¸° ì œí•œ ê°•ì œ
 */
export class DeliverableSizeEnforcer {
  /**
   * íŒŒì¼ ìƒì„± ì „ í¬ê¸° ê²€ì¦
   */
  async validateBeforeWrite(
    filename: string,
    content: string,
    workspacePath: string
  ): Promise<ValidationResult> {
    // 1. íŒŒì¼ í¬ê¸° ê²€ì¦
    const contentSize = Buffer.byteLength(content, 'utf-8');
    const fileValidation = FileSizeValidator.validateFileSize(filename, contentSize);

    if (!fileValidation.valid) {
      return {
        allowed: false,
        reason: 'file_too_large',
        error: fileValidation.error,
        actualSize: contentSize,
        maxSize: fileValidation.maxSize,
      };
    }

    // 2. Workspace ì „ì²´ í¬ê¸° í™•ì¸
    const workspaceInfo = await FileSizeValidator.checkWorkspaceSize(workspacePath);

    if (workspaceInfo.exceedsSizeLimit) {
      return {
        allowed: false,
        reason: 'workspace_size_exceeded',
        error: `Workspace size limit exceeded: ${FileSizeValidator.formatBytes(workspaceInfo.totalSize)} > ${FileSizeValidator.formatBytes(workspaceInfo.maxTotalSize)}`,
        workspaceSize: workspaceInfo.totalSize,
        workspaceLimit: workspaceInfo.maxTotalSize,
      };
    }

    if (workspaceInfo.exceedsFileCountLimit) {
      return {
        allowed: false,
        reason: 'file_count_exceeded',
        error: `File count limit exceeded: ${workspaceInfo.fileCount} > ${workspaceInfo.maxFileCount}`,
        fileCount: workspaceInfo.fileCount,
        maxFileCount: workspaceInfo.maxFileCount,
      };
    }

    // 3. ê²½ê³ : 80% ì´ìƒ ì‚¬ìš© ì‹œ
    if (workspaceInfo.percentUsed >= 80) {
      console.warn(`âš ï¸  Workspace usage high: ${workspaceInfo.percentUsed.toFixed(1)}%`);
    }

    return {
      allowed: true,
      actualSize: contentSize,
      maxSize: fileValidation.maxSize,
      workspaceUsage: workspaceInfo.percentUsed,
    };
  }

  /**
   * ê³¼ë„í•˜ê²Œ í° íŒŒì¼ ê±°ë¶€ ë° Agent í”¼ë“œë°±
   */
  async handleOversizedDeliverable(
    taskId: string,
    filename: string,
    actualSize: number,
    maxSize: number
  ): Promise<void> {
    console.error(`âŒ Oversized deliverable rejected:`, {
      taskId,
      filename,
      actualSize: FileSizeValidator.formatBytes(actualSize),
      maxSize: FileSizeValidator.formatBytes(maxSize),
    });

    // Agentì— í”¼ë“œë°± ì „ì†¡
    await this.sendFeedbackToAgent(taskId, {
      type: 'deliverable_rejected',
      reason: 'file_too_large',
      filename,
      actualSize: FileSizeValidator.formatBytes(actualSize),
      maxSize: FileSizeValidator.formatBytes(maxSize),
      suggestion: 'Please split the file into smaller modules or reduce content size.',
    });

    // ë©”íŠ¸ë¦­ ê¸°ë¡
    metrics.increment('deliverable.rejected.size_exceeded', {
      taskId,
      filename,
    });
  }

  /**
   * ê³¼ë„í•˜ê²Œ í° íŒŒì¼ ìë™ ì •ë¦¬
   */
  async cleanupOversizedFiles(workspacePath: string): Promise<CleanupResult> {
    const workspaceInfo = await FileSizeValidator.checkWorkspaceSize(workspacePath);

    const deletedFiles: string[] = [];
    let freedSpace = 0;

    for (const oversizedFile of workspaceInfo.oversizedFiles) {
      try {
        const stats = await fs.stat(oversizedFile);
        await fs.unlink(oversizedFile);

        deletedFiles.push(oversizedFile);
        freedSpace += stats.size;

        console.log(`ğŸ—‘ï¸  Oversized file deleted: ${oversizedFile} (${FileSizeValidator.formatBytes(stats.size)})`);
      } catch (error) {
        console.error(`Failed to delete oversized file: ${oversizedFile}`, error);
      }
    }

    return {
      deletedCount: deletedFiles.length,
      freedSpace,
      deletedFiles,
    };
  }
}

interface ValidationResult {
  allowed: boolean;
  reason?: string;
  error?: string;
  actualSize?: number;
  maxSize?: number;
  workspaceSize?: number;
  workspaceLimit?: number;
  fileCount?: number;
  maxFileCount?: number;
  workspaceUsage?: number;
}

interface CleanupResult {
  deletedCount: number;
  freedSpace: number;
  deletedFiles: string[];
}
```

#### 5. Monitoring and Alerting

```typescript
// packages/agent-manager/src/monitoring/FileSizeMetrics.ts

/**
 * íŒŒì¼ í¬ê¸° ëª¨ë‹ˆí„°ë§ ë° ë©”íŠ¸ë¦­
 */
export class FileSizeMetrics {
  /**
   * íŒŒì¼ í¬ê¸° ì´ˆê³¼ ì¶”ì 
   */
  trackOversizedFile(
    taskId: string,
    filename: string,
    actualSize: number,
    maxSize: number
  ): void {
    metrics.increment('file.size_exceeded', {
      taskId,
      exceedBy: actualSize - maxSize,
    });

    metrics.histogram('file.size_bytes', actualSize, {
      filename: path.extname(filename),
    });

    // ìƒì„¸ ë¡œê·¸
    logger.warn('Oversized file detected', {
      taskId,
      filename,
      actualSize: FileSizeValidator.formatBytes(actualSize),
      maxSize: FileSizeValidator.formatBytes(maxSize),
      percentOver: ((actualSize / maxSize - 1) * 100).toFixed(1) + '%',
    });
  }

  /**
   * Workspace ì‚¬ìš©ëŸ‰ ì¶”ì 
   */
  trackWorkspaceUsage(taskId: string, info: WorkspaceSizeInfo): void {
    metrics.gauge('workspace.total_size_bytes', info.totalSize, { taskId });
    metrics.gauge('workspace.file_count', info.fileCount, { taskId });
    metrics.gauge('workspace.percent_used', info.percentUsed, { taskId });

    // 80% ì´ìƒ ì‚¬ìš© ì‹œ ì•Œë¦¼
    if (info.percentUsed >= 80) {
      logger.warn('Workspace usage high', {
        taskId,
        percentUsed: info.percentUsed.toFixed(1) + '%',
        totalSize: FileSizeValidator.formatBytes(info.totalSize),
      });
    }

    // 100% ì´ˆê³¼ ì‹œ ê¸´ê¸‰ ì•Œë¦¼
    if (info.exceedsSizeLimit) {
      logger.error('Workspace size limit exceeded', {
        taskId,
        totalSize: FileSizeValidator.formatBytes(info.totalSize),
        limit: FileSizeValidator.formatBytes(info.maxTotalSize),
      });

      // Slack/ì´ë©”ì¼ ì•Œë¦¼
      this.sendSizeAlert(taskId, info);
    }
  }

  /**
   * í¬ê¸° ì œí•œ ì´ˆê³¼ ì•Œë¦¼ ì „ì†¡
   */
  private sendSizeAlert(taskId: string, info: WorkspaceSizeInfo): void {
    // Implement alert logic
    console.error(`ğŸš¨ SIZE ALERT: Task ${taskId} exceeded workspace limit`);
  }
}
```

#### 6. Unit Tests

```typescript
// packages/shared/tests/fileSizeValidator.test.ts

import { FileSizeValidator } from '../src/utils/fileSizeValidator';
import { FILE_SIZE_LIMITS } from '../src/config/fileSizeLimits';

describe('FileSizeValidator', () => {
  test('accepts file within size limit', () => {
    const result = FileSizeValidator.validateFileSize(
      'index.ts',
      5 * 1024 * 1024 // 5 MB
    );

    expect(result.valid).toBe(true);
  });

  test('rejects file exceeding size limit', () => {
    const result = FileSizeValidator.validateFileSize(
      'huge_file.ts',
      20 * 1024 * 1024 // 20 MB (exceeds 10 MB limit for .ts)
    );

    expect(result.valid).toBe(false);
    expect(result.error).toContain('exceeds limit');
  });

  test('applies correct limit per file type', () => {
    expect(getFileSizeLimit('script.js')).toBe(FILE_SIZE_LIMITS.sourceCode.maxSize);
    expect(getFileSizeLimit('README.md')).toBe(FILE_SIZE_LIMITS.documentation.maxSize);
    expect(getFileSizeLimit('config.json')).toBe(FILE_SIZE_LIMITS.configuration.maxSize);
  });

  test('formats bytes correctly', () => {
    expect(FileSizeValidator.formatBytes(1024)).toBe('1.00 KB');
    expect(FileSizeValidator.formatBytes(1024 * 1024)).toBe('1.00 MB');
    expect(FileSizeValidator.formatBytes(1024 * 1024 * 1024)).toBe('1.00 GB');
  });
});
```

#### ì˜ˆì‹œ ì‹œë‚˜ë¦¬ì˜¤

**ì‹œë‚˜ë¦¬ì˜¤ 1: ê³¼ë„í•˜ê²Œ í° ì†ŒìŠ¤ ì½”ë“œ íŒŒì¼**

```typescript
// Agent ì‹œë„: 15MB í¬ê¸°ì˜ index.ts ìƒì„±
const content = 'x'.repeat(15 * 1024 * 1024);

const validation = FileSizeValidator.validateFileSize('index.ts', content.length);
// â†’ { valid: false, error: "File size exceeds limit: 15.00 MB > 10.00 MB" }

// ê²°ê³¼: íŒŒì¼ ìƒì„± ê±°ë¶€, Agentì— í”¼ë“œë°± ì „ì†¡
// í”¼ë“œë°±: "Please split the file into smaller modules"
```

**ì‹œë‚˜ë¦¬ì˜¤ 2: Workspace í¬ê¸° ì œí•œ ì´ˆê³¼**

```typescript
const workspaceInfo = await FileSizeValidator.checkWorkspaceSize('/projects/task_123');

if (workspaceInfo.exceedsSizeLimit) {
  console.error('Workspace size limit exceeded:', {
    totalSize: FileSizeValidator.formatBytes(workspaceInfo.totalSize),
    limit: FileSizeValidator.formatBytes(workspaceInfo.maxTotalSize),
  });

  // ìë™ ì •ë¦¬ ì‹¤í–‰
  const cleanup = await sizeEnforcer.cleanupOversizedFiles('/projects/task_123');
  // â†’ ê³¼ë„í•˜ê²Œ í° íŒŒì¼ ì‚­ì œ
}
```

**ì‹œë‚˜ë¦¬ì˜¤ 3: ìŠ¤íŠ¸ë¦¬ë° íŒŒì¼ ì“°ê¸°**

```typescript
// ëŒ€ìš©ëŸ‰ ë¡œê·¸ íŒŒì¼ì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì“°ê¸°
const logStream = createReadStream('large_log.txt');

await writeStreamingSafe(
  '/projects/task_123/output.log',
  logStream,
  100 * 1024 * 1024 // 100 MB limit
);

// ê²°ê³¼: ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ íŒŒì¼ ìƒì„±
```

### ê¶Œì¥ ì„¤ì •

**í”„ë¡œë•ì…˜**:
- ì†ŒìŠ¤ ì½”ë“œ: 10 MB max
- ë¬¸ì„œ: 5 MB max
- Checkpoint: 50 MB max
- Workspace ì „ì²´: 500 MB max
- ì´ˆê³¼ ì‹œ íŒŒì¼ ìƒì„± ì°¨ë‹¨

**ê°œë°œ**:
- ì œí•œ ì™„í™” (í…ŒìŠ¤íŠ¸ ëª©ì )
- ê²½ê³ ë§Œ ì¶œë ¥, ìƒì„± í—ˆìš©

**ëª¨ë‹ˆí„°ë§**:
- Workspace ì‚¬ìš©ëŸ‰ ì‹¤ì‹œê°„ ì¶”ì 
- 80% ì´ìƒ ì‚¬ìš© ì‹œ ê²½ê³ 
- 100% ì´ˆê³¼ ì‹œ ì•Œë¦¼ ë° ìë™ ì •ë¦¬

---

## Checkpoint ë³µêµ¬ í”„ë¡œì„¸ìŠ¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ì‹œìŠ¤í…œ ì¬ì‹œì‘ í›„ ìë™ ë³µêµ¬

```typescript
async function bootstrapSystem(): Promise<void> {
  console.log('ğŸ”„ System starting... Checking for interrupted tasks');

  // 1. Workspace ìŠ¤ìº”í•˜ì—¬ Task ë°œê²¬
  const projectsDir = '/projects/';
  const taskDirs = await fs.readdir(projectsDir);

  for (const taskDir of taskDirs) {
    const taskId = taskDir;
    const workspacePath = path.join(projectsDir, taskId);

    // 2. Task ë©”íƒ€ë°ì´í„° ì½ê¸°
    const metadataPath = path.join(workspacePath, '.metadata', 'task.json');
    if (!await fs.exists(metadataPath)) continue;

    const taskMetadata = JSON.parse(await fs.readFile(metadataPath, 'utf-8'));

    // 3. ì¤‘ë‹¨ëœ Taskì¸ì§€ í™•ì¸
    if (taskMetadata.status === 'in_progress' || taskMetadata.status === 'paused') {
      console.log(`ğŸ“‹ Found interrupted task: ${taskId}`);

      // 4. ìµœì‹  Checkpoint ë¡œë“œ
      const restored = await restoreFromCheckpoint(taskId);

      if (restored) {
        console.log(`âœ… Task ${taskId} restored successfully`);
      } else {
        console.log(`âŒ Failed to restore task ${taskId}`);
      }
    }
  }

  console.log('âœ… System bootstrap complete');
}
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: Rate Limit í›„ ìë™ ë³µêµ¬

```typescript
async function handleRateLimit(taskId: string, resetTime: Date): Promise<void> {
  console.log(`â¸ï¸  Rate limit hit for task ${taskId}`);

  // 1. Checkpoint ìƒì„±
  const checkpoint = await createCheckpoint(taskId, 'rate_limit');
  await saveCheckpoint(checkpoint);

  // 2. Agent ì¼ì‹œì¤‘ì§€
  const agent = await getAgent(taskId);
  agent.process.kill('SIGTSTP');

  // 3. ìƒíƒœ ì—…ë°ì´íŠ¸
  await updateAgentStatus(taskId, 'paused');

  // 4. Reset ì‹œê°„ ê³„ì‚°
  const waitMs = resetTime.getTime() - Date.now();
  console.log(`â° Waiting ${waitMs}ms until rate limit resets`);

  // 5. ìŠ¤ì¼€ì¤„ëŸ¬ì— ì¬ê°œ ì‘ì—… ë“±ë¡
  setTimeout(async () => {
    console.log(`ğŸ”„ Rate limit reset. Resuming task ${taskId}`);
    await restoreFromCheckpoint(taskId, checkpoint.id);
  }, waitMs);
}
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: ìˆ˜ë™ ë³µêµ¬ (ì‚¬ìš©ìê°€ "ì¬ê°œ" í´ë¦­)

```typescript
async function resumeTask(taskId: string): Promise<void> {
  console.log(`â–¶ï¸  User requested resume for task ${taskId}`);

  // 1. ìµœì‹  Checkpoint í™•ì¸
  const checkpoint = await getLatestCheckpoint(taskId);

  if (!checkpoint) {
    throw new Error('No checkpoint found to resume from');
  }

  // 2. Checkpointì—ì„œ ë³µêµ¬
  await restoreFromCheckpoint(taskId, checkpoint.id);

  console.log(`âœ… Task ${taskId} resumed`);
}
```

### ë³µêµ¬ êµ¬í˜„

```typescript
async function restoreFromCheckpoint(
  taskId: string,
  checkpointId?: string
): Promise<boolean> {
  try {
    // 1. Checkpoint ë¡œë“œ
    const checkpoint = checkpointId
      ? await loadCheckpoint(taskId, checkpointId)
      : await loadLatestCheckpoint(taskId);

    if (!checkpoint) {
      console.error(`No checkpoint found for task ${taskId}`);
      return false;
    }

    console.log(`ğŸ“‚ Loading checkpoint: ${checkpoint.id}`);

    // 2. Workspace ê²€ì¦
    const workspaceValid = await validateWorkspace(checkpoint.workspace);
    if (!workspaceValid) {
      console.error('Workspace validation failed');
      return false;
    }

    // 3. Agent í”„ë¡œì„¸ìŠ¤ ìƒì„±
    const agent = await createAgent({
      taskId: checkpoint.taskId,
      taskType: checkpoint.task.type,
      workingDir: checkpoint.workspace.path,
    });

    // 4. í™˜ê²½ ë³€ìˆ˜ ì¬ì£¼ì…
    await injectEnvironmentVariables(agent, checkpoint.environment);

    // 5. ëŒ€í™” íˆìŠ¤í† ë¦¬ ë³µì›
    await restoreConversationHistory(agent, checkpoint.conversationHistory);

    // 6. Agent ìƒíƒœ ë³µì›
    await updateAgentStatus(taskId, checkpoint.agent.status);

    // 7. Agent ì¬ê°œ (SIGCONT)
    if (checkpoint.agent.status === 'running') {
      agent.process.kill('SIGCONT');
    }

    console.log(`âœ… Checkpoint restored: ${checkpoint.id}`);
    return true;

  } catch (error) {
    console.error(`âŒ Checkpoint restore failed:`, error);
    return false;
  }
}
```

---

## Checkpoint ì—†ëŠ” ìƒíƒœ ë³µêµ¬ (Cold Start Recovery)

Agentê°€ ì²« ë²ˆì§¸ checkpoint ìƒì„± ì „ì— crashí•˜ê±°ë‚˜, ëª¨ë“  checkpointê°€ ì†ìƒëœ ê²½ìš°ì—ëŠ” checkpoint ì—†ì´ ë³µêµ¬ë¥¼ ì‹œë„í•´ì•¼ í•©ë‹ˆë‹¤.

### ë°œìƒ ì‹œë‚˜ë¦¬ì˜¤

1. **ì´ˆê¸° crash**: Agentê°€ ì‹œì‘ í›„ 5ë¶„ ì´ë‚´ (ì²« checkpoint ì „) crash
2. **Checkpoint ì†ìƒ**: ëª¨ë“  checkpoint íŒŒì¼ì´ ì†ìƒë˜ê±°ë‚˜ ì½ì„ ìˆ˜ ì—†ìŒ
3. **Disk ì¥ì• **: Checkpoint ë””ë ‰í† ë¦¬ ì „ì²´ê°€ ì†ì‹¤ë¨
4. **ìˆ˜ë™ ì‚­ì œ**: ì‚¬ìš©ìê°€ `.checkpoints/` ë””ë ‰í† ë¦¬ ì‚­ì œ

### Cold Start ë³µêµ¬ ì „ëµ

Checkpointê°€ ì—†ì„ ë•ŒëŠ” **Best-effort recovery**ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤:

1. Task ë©”íƒ€ë°ì´í„°ì—ì„œ ê¸°ë³¸ ì •ë³´ ë¡œë“œ
2. Workspaceë¥¼ ìŠ¤ìº”í•˜ì—¬ ê¸°ì¡´ ì‚°ì¶œë¬¼ ë°œê²¬
3. ì‚°ì¶œë¬¼ íŒ¨í„´ìœ¼ë¡œ ë§ˆì§€ë§‰ ì™„ë£Œ Phase ì¶”ë¡ 
4. ë‹¤ìŒ Phase ë˜ëŠ” í˜„ì¬ Phase ì²˜ìŒë¶€í„° ì¬ì‹œì‘

### TypeScript êµ¬í˜„

```typescript
// packages/agent-manager/src/recovery/ColdStartRecovery.ts

import fs from 'fs/promises';
import path from 'path';

/**
 * Checkpoint ì—†ì´ Task ë³µêµ¬
 */
export class ColdStartRecovery {
  /**
   * Checkpoint ì—†ëŠ” ìƒíƒœì—ì„œ ë³µêµ¬ ì‹œë„
   */
  async recoverWithoutCheckpoint(taskId: string): Promise<RecoveryResult> {
    console.warn(`âš ï¸  No checkpoint found for task ${taskId}. Attempting cold start recovery...`);

    try {
      // 1. Task ë©”íƒ€ë°ì´í„° ë¡œë“œ
      const metadata = await this.loadTaskMetadata(taskId);
      if (!metadata) {
        throw new Error('Task metadata not found. Cannot recover.');
      }

      // 2. Workspace ìŠ¤ìº”í•˜ì—¬ ì‚°ì¶œë¬¼ ë°œê²¬
      const workspace = `/projects/${taskId}`;
      const deliverables = await this.scanWorkspace(workspace);

      // 3. ë§ˆì§€ë§‰ ì™„ë£Œ Phase ì¶”ë¡ 
      const lastCompletedPhase = this.inferLastCompletedPhase(
        metadata.workflowType,
        deliverables
      );

      // 4. ì¬ì‹œì‘í•  Phase ê²°ì •
      const restartPhase = lastCompletedPhase !== null
        ? lastCompletedPhase + 1
        : 1;

      console.log(`ğŸ“Š Cold start analysis:`);
      console.log(`   - Task type: ${metadata.workflowType}`);
      console.log(`   - Deliverables found: ${deliverables.length} files`);
      console.log(`   - Last completed phase: ${lastCompletedPhase ?? 'None'}`);
      console.log(`   - Restart from: Phase ${restartPhase}`);

      // 5. Agent ì¬ì‹œì‘
      const agent = await this.restartAgent(taskId, {
        workflowType: metadata.workflowType,
        startPhase: restartPhase,
        userPrompt: metadata.userPrompt,
        partialContext: this.buildPartialContext(deliverables),
      });

      // 6. ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
      await this.notifyUserOfColdStart(taskId, {
        lastCompletedPhase,
        restartPhase,
        potentialDataLoss: true,
      });

      return {
        success: true,
        recoveryType: 'cold_start',
        restartedPhase: restartPhase,
        warnings: [
          'Conversation history lost (no checkpoint)',
          'Intermediate thinking/planning lost',
          `Restarting from Phase ${restartPhase}`,
        ],
      };

    } catch (error) {
      console.error(`âŒ Cold start recovery failed:`, error);
      return {
        success: false,
        recoveryType: 'cold_start',
        error: error.message,
      };
    }
  }

  /**
   * Task ë©”íƒ€ë°ì´í„° ë¡œë“œ
   */
  private async loadTaskMetadata(taskId: string): Promise<TaskMetadata | null> {
    try {
      const metadataPath = path.join('/projects', taskId, '.metadata', 'task.json');
      const content = await fs.readFile(metadataPath, 'utf-8');
      return JSON.parse(content);
    } catch {
      return null;
    }
  }

  /**
   * Workspace ìŠ¤ìº”í•˜ì—¬ ê¸°ì¡´ ì‚°ì¶œë¬¼ ë°œê²¬
   */
  private async scanWorkspace(workspacePath: string): Promise<Deliverable[]> {
    const deliverables: Deliverable[] = [];

    try {
      // docs/planning/ ìŠ¤ìº”
      const planningDir = path.join(workspacePath, 'docs', 'planning');
      if (await this.dirExists(planningDir)) {
        const files = await fs.readdir(planningDir);
        for (const file of files) {
          if (file.endsWith('.md')) {
            const content = await fs.readFile(path.join(planningDir, file), 'utf-8');
            deliverables.push({
              phase: 1,
              file: `docs/planning/${file}`,
              size: content.length,
            });
          }
        }
      }

      // docs/design/ ìŠ¤ìº”
      const designDir = path.join(workspacePath, 'docs', 'design');
      if (await this.dirExists(designDir)) {
        const files = await fs.readdir(designDir);
        for (const file of files) {
          if (file.endsWith('.md')) {
            const content = await fs.readFile(path.join(designDir, file), 'utf-8');
            deliverables.push({
              phase: 2,
              file: `docs/design/${file}`,
              size: content.length,
            });
          }
        }
      }

      // src/ ìŠ¤ìº” (ì½”ë“œ íŒŒì¼)
      const srcDir = path.join(workspacePath, 'src');
      if (await this.dirExists(srcDir)) {
        const files = await this.recursiveScan(srcDir);
        for (const file of files) {
          deliverables.push({
            phase: 3,
            file: path.relative(workspacePath, file),
            size: (await fs.stat(file)).size,
          });
        }
      }

      return deliverables;
    } catch (error) {
      console.warn(`âš ï¸  Workspace scan failed:`, error);
      return [];
    }
  }

  /**
   * ì‚°ì¶œë¬¼ íŒ¨í„´ìœ¼ë¡œ ë§ˆì§€ë§‰ ì™„ë£Œ Phase ì¶”ë¡ 
   */
  private inferLastCompletedPhase(
    workflowType: string,
    deliverables: Deliverable[]
  ): number | null {
    if (deliverables.length === 0) return null;

    const phaseGroups = new Map<number, Deliverable[]>();
    for (const d of deliverables) {
      if (!phaseGroups.has(d.phase)) {
        phaseGroups.set(d.phase, []);
      }
      phaseGroups.get(d.phase)!.push(d);
    }

    // Phaseë³„ ì™„ë£Œ ì—¬ë¶€ ê²€ì¦
    if (workflowType === 'create_app') {
      // Phase 1: 9ê°œ planning ë¬¸ì„œ í•„ìš”
      const phase1Files = phaseGroups.get(1) || [];
      const phase1Complete = phase1Files.length >= 9 &&
        phase1Files.every(d => d.size >= 500);

      // Phase 2: 5ê°œ design ë¬¸ì„œ í•„ìš”
      const phase2Files = phaseGroups.get(2) || [];
      const phase2Complete = phase2Files.length >= 5 &&
        phase2Files.every(d => d.size >= 500);

      // Phase 3: ì½”ë“œ íŒŒì¼ ì¡´ì¬
      const phase3Files = phaseGroups.get(3) || [];
      const phase3Complete = phase3Files.length > 0;

      if (phase3Complete) return 3;
      if (phase2Complete) return 2;
      if (phase1Complete) return 1;
      return null;

    } else if (workflowType === 'modify_app') {
      // Phase 1: analysis doc
      const phase1Complete = phaseGroups.has(1);
      // Phase 2: modification plan
      const phase2Complete = phaseGroups.has(2);

      if (phase2Complete) return 2;
      if (phase1Complete) return 1;
      return null;

    } else {
      // ê¸°íƒ€ workflow: Phase ë²ˆí˜¸ ê¸°ì¤€
      const maxPhase = Math.max(...Array.from(phaseGroups.keys()));
      return maxPhase;
    }
  }

  /**
   * ë¶€ë¶„ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ì‚°ì¶œë¬¼ ìš”ì•½)
   */
  private buildPartialContext(deliverables: Deliverable[]): string {
    if (deliverables.length === 0) {
      return 'No previous deliverables found. Starting fresh.';
    }

    const summary = deliverables
      .map(d => `- ${d.file} (${d.size} bytes, Phase ${d.phase})`)
      .join('\n');

    return `
Previous deliverables found in workspace:
${summary}

Note: Due to cold start recovery, conversation history and intermediate thinking are lost.
Please review existing deliverables and continue from where the task was interrupted.
    `.trim();
  }

  /**
   * ì‚¬ìš©ìì—ê²Œ Cold Start ì•Œë¦¼
   */
  private async notifyUserOfColdStart(
    taskId: string,
    info: { lastCompletedPhase: number | null; restartPhase: number; potentialDataLoss: boolean }
  ): Promise<void> {
    const notification = {
      type: 'warning',
      title: 'Task Recovered (Cold Start)',
      message: `
Task ${taskId} has been recovered without a checkpoint.

âš ï¸  Potential data loss:
- Conversation history (user questions answered)
- Intermediate thinking and planning
- Exact agent state

âœ… Recovered information:
- Task type and user prompt
- Existing deliverables (${info.lastCompletedPhase ?? 0} phases worth)

ğŸ”„ Restart plan:
- Resuming from Phase ${info.restartPhase}
${info.lastCompletedPhase !== null ? `- Previous work (up to Phase ${info.lastCompletedPhase}) will be reused` : '- Starting from scratch'}
      `.trim(),
    };

    // Send notification via platform
    await this.sendNotification(taskId, notification);
  }

  // Utility methods
  private async dirExists(dirPath: string): Promise<boolean> {
    try {
      const stat = await fs.stat(dirPath);
      return stat.isDirectory();
    } catch {
      return false;
    }
  }

  private async recursiveScan(dirPath: string): Promise<string[]> {
    const files: string[] = [];
    const entries = await fs.readdir(dirPath, { withFileTypes: true });

    for (const entry of entries) {
      const fullPath = path.join(dirPath, entry.name);
      if (entry.isDirectory()) {
        files.push(...await this.recursiveScan(fullPath));
      } else {
        files.push(fullPath);
      }
    }

    return files;
  }
}

interface RecoveryResult {
  success: boolean;
  recoveryType: 'cold_start';
  restartedPhase?: number;
  warnings?: string[];
  error?: string;
}

interface TaskMetadata {
  taskId: string;
  workflowType: string;
  userPrompt: string;
  createdAt: string;
  status: string;
}

interface Deliverable {
  phase: number;
  file: string;
  size: number;
}
```

### ë³µêµ¬ ì˜ì‚¬ê²°ì • íŠ¸ë¦¬

```
Agent crashes or restarts
  â†“
Has recent checkpoint? (< 30 min)
  â”œâ”€ YES â†’ Restore from checkpoint (normal recovery)
  â””â”€ NO â†’ Check for ANY checkpoint
      â”œâ”€ YES â†’ Restore from older checkpoint
      â”‚         â””â”€ Warn user about potential loss (30+ min of work)
      â””â”€ NO â†’ Cold Start Recovery
          â”œâ”€ Load task metadata
          â”œâ”€ Scan workspace for deliverables
          â”œâ”€ Infer last completed phase
          â”œâ”€ Restart from next/current phase
          â””â”€ Notify user of data loss
```

### ì œí•œ ì‚¬í•­ ë° íŠ¸ë ˆì´ë“œì˜¤í”„

Cold Start ë³µêµ¬ì˜ í•œê³„:

1. **ëŒ€í™” íˆìŠ¤í† ë¦¬ ì†ì‹¤**
   - ì‚¬ìš©ìê°€ ë‹µë³€í•œ ì§ˆë¬¸ë“¤ (USER_QUESTION) ì†ì‹¤
   - Agentê°€ ë°›ì€ ì˜ì¡´ì„± (DEPENDENCY_REQUEST) ì†ì‹¤
   - âš ï¸ ê²°ê³¼: Agentê°€ ë™ì¼í•œ ì§ˆë¬¸ì„ ë‹¤ì‹œ í•  ìˆ˜ ìˆìŒ

2. **ì¤‘ê°„ ì‚¬ê³  ê³¼ì • ì†ì‹¤**
   - Agentì˜ ë‚´ë¶€ ì¶”ë¡  ê³¼ì • ì†ì‹¤
   - ê³„íš ë° ë””ìì¸ ê²°ì •ì˜ ê·¼ê±° ì†ì‹¤
   - âš ï¸ ê²°ê³¼: Agentê°€ ë‹¤ë¥¸ ì ‘ê·¼ ë°©ì‹ì„ ì„ íƒí•  ìˆ˜ ìˆìŒ

3. **ì •í™•í•œ ì§„í–‰ ìƒíƒœ íŒŒì•… ë¶ˆê°€**
   - PhaseëŠ” ì¶”ë¡  ê°€ëŠ¥í•˜ì§€ë§Œ Phase ë‚´ ì§„í–‰ë¥ ì€ ë¶ˆëª…í™•
   - âš ï¸ ê²°ê³¼: ì¼ë¶€ ì¤‘ë³µ ì‘ì—… ê°€ëŠ¥ì„±

4. **ë¶€ë¶„ ì™„ë£Œëœ Phase ì²˜ë¦¬ ì–´ë ¤ì›€**
   - Phase 1ì´ 80% ì™„ë£Œë˜ì—ˆë‹¤ê°€ crash â†’ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘
   - âš ï¸ ê²°ê³¼: ì¤‘ë³µ ì‘ì—… ë°œìƒ

### ì™„í™” ì „ëµ

ì´ëŸ¬í•œ í•œê³„ë¥¼ ì¤„ì´ê¸° ìœ„í•œ ì „ëµ:

1. **ë¹ ë¥¸ ì²« Checkpoint**
   - ì‹œì‘ í›„ 5ë¶„ ì´ë‚´ ì²« checkpoint ìƒì„±
   - â†’ Cold start ê°€ëŠ¥ì„± ìµœì†Œí™”

2. **ë‹¤ì¤‘ Checkpoint ë³´ì¡´**
   - ìµœì†Œ 3ê°œì˜ checkpoint ë³´ê´€ (7ì¼ê°„)
   - â†’ ë‹¨ì¼ checkpoint ì†ìƒì—ë„ ë³µêµ¬ ê°€ëŠ¥

3. **ì‚¬ìš©ì ì•Œë¦¼**
   - Cold start ë°œìƒ ì‹œ ëª…í™•í•œ ê²½ê³  ë©”ì‹œì§€
   - ì ì¬ì  ë°ì´í„° ì†ì‹¤ ì„¤ëª…
   - ì¬ì‹œì‘ ê³„íš ì„¤ëª…

4. **ì‚°ì¶œë¬¼ ê¸°ë°˜ ì¬ê°œ**
   - ê¸°ì¡´ ì‚°ì¶œë¬¼ ìµœëŒ€í•œ í™œìš©
   - Phase ì¬ì‹œì‘ ì‹œ ê¸°ì¡´ íŒŒì¼ ê²€í† 
   - ë¶ˆí•„ìš”í•œ ì¤‘ë³µ ì‘ì—… ë°©ì§€

### ì˜ˆì‹œ ì‹œë‚˜ë¦¬ì˜¤

#### ì‹œë‚˜ë¦¬ì˜¤ 1: Phase 1 80% ì™„ë£Œ ì‹œ Crash (Checkpoint ì—†ìŒ)

```
[Before Crash]
- Phase 1 ì§„í–‰ ì¤‘ (80% complete)
- 9ê°œ ë¬¸ì„œ ì¤‘ 7ê°œ ì‘ì„± ì™„ë£Œ
- 2ê°œ ë¬¸ì„œ ì‘ì„± ì¤‘ (ì•„ì§ ì €ì¥ ì•ˆ ë¨)
- ì²« checkpoint ìƒì„± ì§ì „ crash

[Cold Start Recovery]
1. Scan workspace: 7ê°œ planning ë¬¸ì„œ ë°œê²¬
2. Infer phase: Phase 1 ë¯¸ì™„ë£Œ (9ê°œ í•„ìš”, 7ê°œë§Œ ì¡´ì¬)
3. Decision: Phase 1 ì²˜ìŒë¶€í„° ì¬ì‹œì‘
4. Result: ê¸°ì¡´ 7ê°œ ë¬¸ì„œ ê²€í†  í›„ ë¶€ì¡±í•œ 2ê°œ + ì „ì²´ ì¬ê²€ì¦
```

#### ì‹œë‚˜ë¦¬ì˜¤ 2: Phase 2 ì™„ë£Œ ì§í›„ Crash (Checkpoint ì—†ìŒ)

```
[Before Crash]
- Phase 2 ë°©ê¸ˆ ì™„ë£Œ
- Phase completion signal ì¶œë ¥ ì™„ë£Œ
- Checkpoint ìƒì„± ì‹œë„ ì¤‘ disk full â†’ crash

[Cold Start Recovery]
1. Scan workspace:
   - 9ê°œ planning ë¬¸ì„œ (Phase 1 ì™„ë£Œ)
   - 5ê°œ design ë¬¸ì„œ (Phase 2 ì™„ë£Œ)
2. Infer phase: Phase 2 ì™„ë£Œ
3. Decision: Phase 3ë¶€í„° ì¬ì‹œì‘
4. Result: Phase 1, 2 ì‚°ì¶œë¬¼ í™œìš©í•˜ì—¬ Phase 3 ê°œë°œ ì‹œì‘
```

#### ì‹œë‚˜ë¦¬ì˜¤ 3: ëª¨ë“  Checkpoint ì†ìƒ

```
[Situation]
- Disk corruptionìœ¼ë¡œ .checkpoints/ ì „ì²´ ì†ìƒ
- TaskëŠ” Phase 3 ê°œë°œ ì¤‘ì´ì—ˆìŒ

[Cold Start Recovery]
1. Scan workspace: Phase 1, 2 ë¬¸ì„œ + ì¼ë¶€ ì½”ë“œ ë°œê²¬
2. Infer phase: Phase 3 ì§„í–‰ ì¤‘
3. Decision: Phase 3 ê³„ì† ì§„í–‰
4. Result:
   - ê¸°ì¡´ ì½”ë“œ ê²€í† 
   - ë¯¸ì™„ì„± ë¶€ë¶„ ì‹ë³„
   - ê°œë°œ ê³„ì†
   âš ï¸  ëŒ€í™” íˆìŠ¤í† ë¦¬ ì†ì‹¤ë¡œ ì¼ë¶€ ê²°ì •ì˜ ê·¼ê±° ë¶ˆëª…í™•
```

### ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­

Cold Start Recovery ì¶”ì :

```typescript
interface ColdStartMetrics {
  totalColdStarts: number;          // ì´ cold start ë°œìƒ íšŸìˆ˜
  coldStartRate: number;            // Cold start ë¹„ìœ¨ (0-1)
  avgRecoveryTime: number;          // í‰ê·  ë³µêµ¬ ì†Œìš” ì‹œê°„ (ms)
  inferenceAccuracy: number;        // Phase ì¶”ë¡  ì •í™•ë„ (0-1)
  userComplaintRate: number;        // ì‚¬ìš©ì ë¶ˆë§Œ ë¹„ìœ¨ (ì¤‘ë³µ ì‘ì—… ë“±)
}
```

**ì•Œë¦¼ ì¡°ê±´**:
- Cold start rate > 5% â†’ Checkpoint ì‹œìŠ¤í…œ ì ê²€ í•„ìš”
- Inference accuracy < 80% â†’ ì‚°ì¶œë¬¼ íŒ¨í„´ ê°ì§€ ë¡œì§ ê°œì„  í•„ìš”

---

## ì—ëŸ¬ ì²˜ë¦¬

### Checkpoint ìƒì„± ì‹¤íŒ¨

```typescript
try {
  await createCheckpoint(taskId, 'interval');
} catch (error) {
  console.error('Failed to create checkpoint:', error);
  // ê³„ì† ì§„í–‰ (Checkpoint ì‹¤íŒ¨ê°€ Agent ì‹¤í–‰ì„ ë§‰ì§€ ì•ŠìŒ)
  // ë‹¤ìŒ intervalì— ì¬ì‹œë„
}
```

### Checkpoint ë³µêµ¬ ì‹¤íŒ¨

```typescript
const restored = await restoreFromCheckpoint(taskId);

if (!restored) {
  // Fallback: Taskë¥¼ ì²˜ìŒë¶€í„° ì¬ì‹œì‘
  console.log('Checkpoint restore failed. Restarting task from beginning');

  // ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
  await notifyUser({
    type: 'warning',
    message: 'Task could not be restored from checkpoint. Restarting from beginning.',
  });

  // Task ì¬ì‹œì‘
  await restartTask(taskId);
}
```

---

## ë™ì‹œì„± ì²˜ë¦¬ (Concurrency Handling)

ì—¬ëŸ¬ Agentê°€ ë™ì‹œì— ì‹¤í–‰ë˜ê±°ë‚˜ ê°™ì€ Agentê°€ ì—¬ëŸ¬ Checkpointë¥¼ ë¹ ë¥´ê²Œ ìƒì„±í•  ë•Œì˜ ì²˜ë¦¬ ì „ëµì…ë‹ˆë‹¤.

### ì‹œë‚˜ë¦¬ì˜¤ 1: ë™ì‹œ Checkpoint ì €ì¥

**ë¬¸ì œ**: ì—¬ëŸ¬ Agentê°€ ë™ì‹œì— Checkpoint ì €ì¥ ì‹œë„

```
Agent A (task_123): Checkpoint ì €ì¥ ìš”ì²­ (10:00:00.100)
Agent B (task_456): Checkpoint ì €ì¥ ìš”ì²­ (10:00:00.150)
Agent C (task_789): Checkpoint ì €ì¥ ìš”ì²­ (10:00:00.200)
```

**í•´ê²°**: Checkpoint ì €ì¥ í ì‚¬ìš©

```typescript
import { Queue } from 'async';

// Checkpoint ì €ì¥ í (ë™ì‹œ ì‹¤í–‰ ì œí•œ: 3)
const checkpointQueue = new Queue(async (task: CheckpointTask) => {
  await saveCheckpointToFile(task);
}, 3); // ìµœëŒ€ 3ê°œ ë™ì‹œ ì €ì¥

function createCheckpoint(taskId: string): Promise<void> {
  return new Promise((resolve, reject) => {
    checkpointQueue.push(
      { taskId, timestamp: Date.now() },
      (error) => {
        if (error) reject(error);
        else resolve();
      }
    );
  });
}
```

**ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­**:
- ë™ì‹œ ì‹¤í–‰ ì œí•œ: 3ê°œ (íŒŒì¼ I/O ë¶€í•˜ ë°©ì§€)
- í í¬ê¸° ì œí•œ: 100 (ë©”ëª¨ë¦¬ ë³´í˜¸)
- í ê°€ë“ ì°¨ë©´: ê°€ì¥ ì˜¤ë˜ëœ ìš”ì²­ë¶€í„° ê±°ë¶€ (ì˜¤ë¥˜ ë¡œê·¸)

### ì‹œë‚˜ë¦¬ì˜¤ 2: ê°™ì€ Agentì˜ ì¤‘ë³µ Checkpoint ìš”ì²­

**ë¬¸ì œ**: Rate limit ê°ì§€ì™€ ìë™ ì£¼ê¸°ê°€ ë™ì‹œì— ë°œìƒ

```
Agent (task_123):
  - 10:00:00: ìë™ ì£¼ê¸° (10ë¶„) â†’ Checkpoint ìš”ì²­
  - 10:00:00.050: Rate limit ê°ì§€ â†’ Checkpoint ìš”ì²­
```

**í•´ê²°**: Debouncing + ì¤‘ë³µ ì œê±°

```typescript
const pendingCheckpoints = new Map<string, NodeJS.Timeout>();

function createCheckpoint(taskId: string, reason: string): void {
  // 1. ì´ë¯¸ ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ì´ ìˆìœ¼ë©´ ì·¨ì†Œ
  if (pendingCheckpoints.has(taskId)) {
    clearTimeout(pendingCheckpoints.get(taskId)!);
  }

  // 2. 100ms debounce (ê°™ì€ ì‹œê°„ëŒ€ ì—¬ëŸ¬ ìš”ì²­ ë³‘í•©)
  const timer = setTimeout(async () => {
    await saveCheckpoint(taskId, reason);
    pendingCheckpoints.delete(taskId);
  }, 100);

  pendingCheckpoints.set(taskId, timer);
}
```

**íš¨ê³¼**:
- 100ms ë‚´ ì—¬ëŸ¬ ìš”ì²­ â†’ 1ê°œë¡œ ë³‘í•©
- ë§ˆì§€ë§‰ reasonì´ ìš°ì„  (Rate limit > auto)
- ë¶ˆí•„ìš”í•œ I/O ë°©ì§€

### ì‹œë‚˜ë¦¬ì˜¤ 3: Checkpoint ì €ì¥ ì¤‘ ë‹¤ìŒ Checkpoint ìš”ì²­

**ë¬¸ì œ**: Checkpoint ì €ì¥ì´ ëŠë¦´ ë•Œ ë‹¤ìŒ ìš”ì²­ì´ ë“¤ì–´ì˜´

```
10:00:00: Agent A Checkpoint ì €ì¥ ì‹œì‘ (5ì´ˆ ì†Œìš”)
10:00:02: Agent A Checkpoint ì €ì¥ ìš”ì²­ (ë‹¤ì‹œ)
10:00:05: ì²« ë²ˆì§¸ ì €ì¥ ì™„ë£Œ
```

**í•´ê²°**: ì €ì¥ ì¤‘ í”Œë˜ê·¸ + í ëŒ€ê¸°

```typescript
const savingCheckpoints = new Set<string>();

async function createCheckpoint(taskId: string): Promise<void> {
  // ì´ë¯¸ ì €ì¥ ì¤‘ì´ë©´ íì— ì¶”ê°€ë§Œ í•˜ê³  ë¦¬í„´
  if (savingCheckpoints.has(taskId)) {
    console.log(`Checkpoint save in progress for ${taskId}, queuing...`);
    return queueCheckpoint(taskId);
  }

  try {
    savingCheckpoints.add(taskId);
    await saveCheckpointToFile(taskId);
  } finally {
    savingCheckpoints.delete(taskId);
  }
}
```

### ì‹œë‚˜ë¦¬ì˜¤ 4: ë‹¤ì¤‘ Agent Manager ì¸ìŠ¤í„´ìŠ¤ (ë¶„ì‚° ì‹œìŠ¤í…œ)

**ë¬¸ì œ**: ì—¬ëŸ¬ Agent Manager ì„œë²„ê°€ ê°™ì€ Agentì˜ Checkpoint ì €ì¥ ì‹œë„

**í•´ê²°**: íŒŒì¼ ì ê¸ˆ (File Locking) ë˜ëŠ” ë¶„ì‚° ì ê¸ˆ

```typescript
import * as fs from 'fs';

async function saveCheckpointWithLock(taskId: string): Promise<void> {
  const lockFile = `/checkpoints/${taskId}.lock`;

  try {
    // 1. ë°°íƒ€ì  ì ê¸ˆ íšë“ ì‹œë„
    const fd = await fs.promises.open(lockFile, 'wx');

    // 2. Checkpoint ì €ì¥
    await saveCheckpointToFile(taskId);

    // 3. ì ê¸ˆ í•´ì œ
    await fd.close();
    await fs.promises.unlink(lockFile);

  } catch (error) {
    if (error.code === 'EEXIST') {
      // ë‹¤ë¥¸ ì¸ìŠ¤í„´ìŠ¤ê°€ ì´ë¯¸ ì €ì¥ ì¤‘
      console.warn(`Checkpoint for ${taskId} is being saved by another instance`);
      return;
    }
    throw error;
  }
}
```

### ë™ì‹œì„± ê°€ë“œë ˆì¼

**Agent Manager ì „ì—­ ì„¤ì •**:

```typescript
const CHECKPOINT_CONFIG = {
  maxConcurrentSaves: 3,          // ìµœëŒ€ ë™ì‹œ ì €ì¥
  queueMaxSize: 100,               // í ìµœëŒ€ í¬ê¸°
  debounceMs: 100,                 // ì¤‘ë³µ ìš”ì²­ ë³‘í•© ì‹œê°„
  saveTimeoutMs: 30000,            // ì €ì¥ íƒ€ì„ì•„ì›ƒ (30ì´ˆ)
  retryAttempts: 3,                // ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ íšŸìˆ˜
};
```

**ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­**:
- í ê¸¸ì´ (queue length)
- í‰ê·  ì €ì¥ ì‹œê°„ (avg save time)
- ì¤‘ë³µ ì œê±°ëœ ìš”ì²­ ìˆ˜ (deduplicated requests)
- ì €ì¥ ì‹¤íŒ¨ íšŸìˆ˜ (failed saves)

---

## ëª¨ë‹ˆí„°ë§ ë° ë¡œê·¸

### Checkpoint ìƒì„± ë¡œê·¸

```json
{
  "timestamp": "2024-02-15T10:30:00Z",
  "type": "checkpoint_created",
  "taskId": "task_xyz789",
  "checkpointId": "checkpoint_abc123",
  "reason": "interval",
  "size": 1024000,
  "duration_ms": 150
}
```

### Checkpoint ë³µêµ¬ ë¡œê·¸

```json
{
  "timestamp": "2024-02-15T10:45:00Z",
  "type": "checkpoint_restored",
  "taskId": "task_xyz789",
  "checkpointId": "checkpoint_abc123",
  "success": true,
  "duration_ms": 500,
  "messages_restored": 25,
  "environment_variables": 3
}
```

---

## ìµœì í™”

### 1. ì¦ë¶„ Checkpoint (Incremental)

ì „ì²´ ìƒíƒœ ëŒ€ì‹  ë³€ê²½ì‚¬í•­ë§Œ ì €ì¥:

```typescript
interface IncrementalCheckpoint {
  baseCheckpointId: string;          // ê¸°ë°˜ì´ ë˜ëŠ” Checkpoint
  changes: {
    conversationHistory: {
      newMessages: ConversationMessage[];
      startIndex: number;
    };
    workspace: {
      newFiles: string[];
      modifiedFiles: string[];
    };
  };
}
```

### 2. ì••ì¶•

```typescript
import { gzip } from 'zlib';
import { promisify } from 'util';

const gzipAsync = promisify(gzip);

async function saveCompressedCheckpoint(checkpoint: Checkpoint): Promise<void> {
  const json = JSON.stringify(checkpoint);
  const compressed = await gzipAsync(json);

  const filepath = `/projects/${checkpoint.taskId}/.checkpoints/${checkpoint.id}.json.gz`;
  await fs.writeFile(filepath, compressed);
}
```

### 3. ë³‘ë ¬ ì €ì¥

```typescript
await Promise.all([
  saveCheckpointToFile(checkpoint),
  saveCheckpointToDB(checkpoint),
  updateWorkspaceMetadata(checkpoint),
]);
```

---

## Checkpoint ë²„ì „ ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ

### ê°œìš”

Checkpoint ë°ì´í„° êµ¬ì¡°ëŠ” ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ì— ë”°ë¼ ë³€ê²½ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ Checkpointì™€ì˜ í˜¸í™˜ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ìƒˆë¡œìš´ êµ¬ì¡°ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ëŠ” ì „ëµì´ í•„ìš”í•©ë‹ˆë‹¤.

### ë²„ì „ ê´€ë¦¬ ì²´ê³„

#### Checkpoint ìŠ¤í‚¤ë§ˆ ë²„ì „

```typescript
interface Checkpoint {
  id: string;
  taskId: string;
  version: string; // "1.0", "1.1", "2.0" ë“±
  schemaVersion: number; // 1, 2, 3 ë“± (ë‚´ë¶€ ë²„ì „)
  createdAt: Date;

  // ì‹¤ì œ ë°ì´í„°
  data: {
    agentState: AgentState;
    conversationHistory: ConversationMessage[];
    workspace: WorkspaceSnapshot;
    environment: Record<string, string>;
  };
}
```

**ë²„ì „ ê´€ë¦¬ ê·œì¹™**:
- **Major ë²„ì „ (1.x â†’ 2.x)**: í˜¸í™˜ì„± ê¹¨ì§€ëŠ” ë³€ê²½ (ë§ˆì´ê·¸ë ˆì´ì…˜ í•„ìˆ˜)
- **Minor ë²„ì „ (1.0 â†’ 1.1)**: í•˜ìœ„ í˜¸í™˜ ê°€ëŠ¥í•œ ì¶”ê°€ (ë§ˆì´ê·¸ë ˆì´ì…˜ ì„ íƒ)
- **Patch ë²„ì „ (1.0.1 â†’ 1.0.2)**: ë²„ê·¸ ìˆ˜ì • (ë§ˆì´ê·¸ë ˆì´ì…˜ ë¶ˆí•„ìš”)

### ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ

#### 1. ì§€ì—° ë§ˆì´ê·¸ë ˆì´ì…˜ (Lazy Migration)

Checkpoint ë¡œë“œ ì‹œ ìë™ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜:

```typescript
// packages/agent-manager/src/CheckpointMigration.ts

export class CheckpointMigrator {
  private migrations: Map<number, Migration> = new Map();

  constructor() {
    // ë§ˆì´ê·¸ë ˆì´ì…˜ í•¨ìˆ˜ ë“±ë¡
    this.registerMigration(1, this.migrateV0toV1);
    this.registerMigration(2, this.migrateV1toV2);
    this.registerMigration(3, this.migrateV2toV3);
  }

  /**
   * Checkpoint ë¡œë“œ ì‹œ ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜
   */
  async loadAndMigrate(checkpointPath: string): Promise<Checkpoint> {
    const raw = await fs.readFile(checkpointPath, 'utf-8');
    const checkpoint = JSON.parse(raw) as Checkpoint;

    const currentVersion = this.getCurrentSchemaVersion();
    const checkpointVersion = checkpoint.schemaVersion || 0;

    if (checkpointVersion === currentVersion) {
      // ìµœì‹  ë²„ì „ - ë§ˆì´ê·¸ë ˆì´ì…˜ ë¶ˆí•„ìš”
      return checkpoint;
    }

    if (checkpointVersion > currentVersion) {
      throw new Error(
        `Checkpoint schema version ${checkpointVersion} is newer than current ${currentVersion}. ` +
        `Please update the system.`
      );
    }

    // ë§ˆì´ê·¸ë ˆì´ì…˜ ìˆ˜í–‰
    console.log(`ğŸ”„ Migrating checkpoint from v${checkpointVersion} to v${currentVersion}`);
    const migrated = await this.migrate(checkpoint, checkpointVersion, currentVersion);

    // ë§ˆì´ê·¸ë ˆì´ì…˜ëœ ë²„ì „ ì €ì¥ (ì„ íƒì )
    if (process.env.SAVE_MIGRATED_CHECKPOINTS === 'true') {
      await this.saveCheckpoint(migrated, checkpointPath);
    }

    return migrated;
  }

  /**
   * ìˆœì°¨ì  ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
   */
  private async migrate(
    checkpoint: Checkpoint,
    fromVersion: number,
    toVersion: number
  ): Promise<Checkpoint> {
    let current = checkpoint;

    for (let v = fromVersion + 1; v <= toVersion; v++) {
      const migration = this.migrations.get(v);
      if (!migration) {
        throw new Error(`Migration to version ${v} not found`);
      }

      console.log(`  â†’ Applying migration v${v - 1} â†’ v${v}`);
      current = await migration(current);
      current.schemaVersion = v;
    }

    return current;
  }

  /**
   * í˜„ì¬ ì‹œìŠ¤í…œì˜ ìŠ¤í‚¤ë§ˆ ë²„ì „
   */
  private getCurrentSchemaVersion(): number {
    return 3; // í˜„ì¬ ìµœì‹  ë²„ì „
  }

  /**
   * ë§ˆì´ê·¸ë ˆì´ì…˜ í•¨ìˆ˜ ë“±ë¡
   */
  private registerMigration(version: number, fn: Migration): void {
    this.migrations.set(version, fn);
  }

  // ========================================
  // ë§ˆì´ê·¸ë ˆì´ì…˜ í•¨ìˆ˜ë“¤
  // ========================================

  /**
   * v0 â†’ v1: conversationHistoryì— role í•„ë“œ ì¶”ê°€
   */
  private migrateV0toV1 = async (checkpoint: any): Promise<Checkpoint> => {
    if (!checkpoint.data.conversationHistory) {
      checkpoint.data.conversationHistory = [];
    }

    // ê¸°ì¡´ ë©”ì‹œì§€ì— role ì¶”ê°€
    checkpoint.data.conversationHistory = checkpoint.data.conversationHistory.map(
      (msg: any) => ({
        ...msg,
        role: msg.role || 'user', // ê¸°ë³¸ê°’: user
      })
    );

    return checkpoint;
  };

  /**
   * v1 â†’ v2: workspaceì— dependencies ì¶”ê°€
   */
  private migrateV1toV2 = async (checkpoint: any): Promise<Checkpoint> => {
    if (!checkpoint.data.workspace.dependencies) {
      checkpoint.data.workspace.dependencies = {
        files: [],
        environment: {},
      };
    }

    return checkpoint;
  };

  /**
   * v2 â†’ v3: agentStateì— currentPhase êµ¬ì¡°í™”
   */
  private migrateV2toV3 = async (checkpoint: any): Promise<Checkpoint> => {
    const oldPhase = checkpoint.data.agentState.phase;

    // phaseë¥¼ êµ¬ì¡°í™”ëœ ê°ì²´ë¡œ ë³€í™˜
    checkpoint.data.agentState.currentPhase = {
      number: oldPhase,
      name: this.getPhaseNameFromNumber(oldPhase),
      status: 'in_progress',
      startedAt: checkpoint.createdAt,
    };

    // êµ¬ë²„ì „ í•„ë“œ ì œê±°
    delete checkpoint.data.agentState.phase;

    return checkpoint;
  };

  private getPhaseNameFromNumber(phase: number): string {
    const names = ['Planning', 'Design', 'Development', 'Testing'];
    return names[phase - 1] || 'Unknown';
  }
}

type Migration = (checkpoint: any) => Promise<Checkpoint>;
```

#### 2. ì¼ê´„ ë§ˆì´ê·¸ë ˆì´ì…˜ (Batch Migration)

ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ ì‹œ ëª¨ë“  Checkpointë¥¼ í•œ ë²ˆì— ë§ˆì´ê·¸ë ˆì´ì…˜:

```typescript
// scripts/migrate-checkpoints.ts

import { glob } from 'glob';
import { CheckpointMigrator } from './CheckpointMigration';

async function batchMigrateCheckpoints() {
  const migrator = new CheckpointMigrator();

  // ëª¨ë“  Checkpoint íŒŒì¼ ì°¾ê¸°
  const checkpointFiles = await glob('/projects/**/.checkpoints/*.json');

  console.log(`Found ${checkpointFiles.length} checkpoints to migrate`);

  let successCount = 0;
  let failureCount = 0;

  for (const filepath of checkpointFiles) {
    try {
      console.log(`Migrating: ${filepath}`);

      // ë¡œë“œ ë° ë§ˆì´ê·¸ë ˆì´ì…˜
      const migrated = await migrator.loadAndMigrate(filepath);

      // ë°±ì—… ìƒì„±
      await fs.copyFile(filepath, `${filepath}.backup`);

      // ë§ˆì´ê·¸ë ˆì´ì…˜ëœ ë²„ì „ ì €ì¥
      await fs.writeFile(filepath, JSON.stringify(migrated, null, 2));

      successCount++;
    } catch (error) {
      console.error(`Failed to migrate ${filepath}:`, error);
      failureCount++;
    }
  }

  console.log(`\nMigration complete:`);
  console.log(`  âœ… Success: ${successCount}`);
  console.log(`  âŒ Failure: ${failureCount}`);
}

// ì‹¤í–‰
batchMigrateCheckpoints().catch(console.error);
```

#### 3. í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€ (Backward Compatibility)

ìƒˆ ê¸°ëŠ¥ ì¶”ê°€ ì‹œ ê¸°ì¡´ Checkpointì™€ í˜¸í™˜ì„± ìœ ì§€:

```typescript
// ìƒˆ í•„ë“œëŠ” Optionalë¡œ ì •ì˜
interface CheckpointV2 {
  id: string;
  taskId: string;
  schemaVersion: number;

  data: {
    agentState: AgentState;
    conversationHistory: ConversationMessage[];
    workspace: WorkspaceSnapshot;
    environment: Record<string, string>;

    // ìƒˆ í•„ë“œ: Optional (v2ì—ì„œ ì¶”ê°€)
    metadata?: {
      tags?: string[];
      priority?: 'low' | 'medium' | 'high';
    };
  };
}

// ë¡œë“œ ì‹œ ê¸°ë³¸ê°’ ì œê³µ
function loadCheckpoint(checkpoint: CheckpointV2): CheckpointV2 {
  return {
    ...checkpoint,
    data: {
      ...checkpoint.data,
      metadata: checkpoint.data.metadata || {
        tags: [],
        priority: 'medium',
      },
    },
  };
}
```

### ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ê´€ë¦¬

#### ë§ˆì´ê·¸ë ˆì´ì…˜ íˆìŠ¤í† ë¦¬

```typescript
// migrations/checkpoint-migrations.ts

export const CHECKPOINT_MIGRATIONS = [
  {
    version: 1,
    date: '2024-01-15',
    description: 'Add role field to conversationHistory',
    breaking: false,
  },
  {
    version: 2,
    date: '2024-02-01',
    description: 'Add dependencies to workspace',
    breaking: false,
  },
  {
    version: 3,
    date: '2024-02-15',
    description: 'Restructure agentState.phase to currentPhase',
    breaking: true,
  },
];

export function getMigrationsSince(version: number): Migration[] {
  return CHECKPOINT_MIGRATIONS.filter(m => m.version > version);
}
```

### ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡¤ë°±

```typescript
export class CheckpointMigrator {
  /**
   * ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨ ì‹œ ë¡¤ë°±
   */
  async migrateWithRollback(checkpoint: Checkpoint): Promise<Checkpoint> {
    const backup = JSON.parse(JSON.stringify(checkpoint)); // Deep copy

    try {
      const migrated = await this.migrate(
        checkpoint,
        checkpoint.schemaVersion || 0,
        this.getCurrentSchemaVersion()
      );

      return migrated;
    } catch (error) {
      console.error('Migration failed, rolling back:', error);

      // ë°±ì—…ì—ì„œ ë³µêµ¬
      return backup;
    }
  }

  /**
   * ê²€ì¦: ë§ˆì´ê·¸ë ˆì´ì…˜ í›„ ë°ì´í„° ë¬´ê²°ì„± í™•ì¸
   */
  private async validateMigration(checkpoint: Checkpoint): Promise<boolean> {
    try {
      // í•„ìˆ˜ í•„ë“œ ì¡´ì¬ í™•ì¸
      if (!checkpoint.id || !checkpoint.taskId) {
        return false;
      }

      // ë°ì´í„° êµ¬ì¡° í™•ì¸
      if (!checkpoint.data.agentState || !checkpoint.data.conversationHistory) {
        return false;
      }

      // ìŠ¤í‚¤ë§ˆ ë²„ì „ í™•ì¸
      if (checkpoint.schemaVersion !== this.getCurrentSchemaVersion()) {
        return false;
      }

      return true;
    } catch {
      return false;
    }
  }
}
```

### ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

```typescript
// ë§ˆì´ê·¸ë ˆì´ì…˜ í†µê³„ ìˆ˜ì§‘
export class MigrationMonitor {
  private stats = {
    total: 0,
    success: 0,
    failure: 0,
    byVersion: new Map<string, number>(),
  };

  recordMigration(
    fromVersion: number,
    toVersion: number,
    success: boolean
  ): void {
    this.stats.total++;

    if (success) {
      this.stats.success++;
    } else {
      this.stats.failure++;
    }

    const key = `${fromVersion}â†’${toVersion}`;
    this.stats.byVersion.set(key, (this.stats.byVersion.get(key) || 0) + 1);
  }

  getStats() {
    return {
      ...this.stats,
      byVersion: Object.fromEntries(this.stats.byVersion),
    };
  }
}
```

### ì‚¬ìš© ê°€ì´ë“œ

#### ê°œë°œìë¥¼ ìœ„í•œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‘ì„± ê°€ì´ë“œ

1. **ìƒˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¶”ê°€ ì‹œ**:
   ```typescript
   // CheckpointMigrator ìƒì„±ìì— ë“±ë¡
   this.registerMigration(4, this.migrateV3toV4);

   // ë§ˆì´ê·¸ë ˆì´ì…˜ í•¨ìˆ˜ ì‘ì„±
   private migrateV3toV4 = async (checkpoint: any): Promise<Checkpoint> => {
     // ë³€ê²½ ì‚¬í•­ êµ¬í˜„
     checkpoint.data.newField = 'default_value';
     return checkpoint;
   };
   ```

2. **ë²„ì „ ë²ˆí˜¸ ì¦ê°€**:
   ```typescript
   private getCurrentSchemaVersion(): number {
     return 4; // 3ì—ì„œ 4ë¡œ ì¦ê°€
   }
   ```

3. **ë§ˆì´ê·¸ë ˆì´ì…˜ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸**:
   ```typescript
   export const CHECKPOINT_MIGRATIONS = [
     // ...existing migrations
     {
       version: 4,
       date: '2024-03-01',
       description: 'Add newField to data',
       breaking: false,
     },
   ];
   ```

4. **í…ŒìŠ¤íŠ¸ ì‘ì„±**:
   ```typescript
   test('migrateV3toV4 adds newField', async () => {
     const v3Checkpoint = { schemaVersion: 3, data: {} };
     const migrated = await migrator.migrateV3toV4(v3Checkpoint);
     expect(migrated.data.newField).toBe('default_value');
   });
   ```

---

## ê´€ë ¨ ë¬¸ì„œ

- **ì›Œí¬í”Œë¡œìš°**: `/docs/WORKFLOWS.md`
- **ìƒíƒœ ê¸°ê³„**: `/docs/STATE_MACHINE.md`
- **Workspace ê´€ë¦¬**: `/packages/agent-manager/docs/workspace/`
- **ìš©ì–´ì§‘**: `/docs/GLOSSARY.md`

---

**ìµœì¢… ì—…ë°ì´íŠ¸**: 2024-02-15
**ë²„ì „**: 1.1
